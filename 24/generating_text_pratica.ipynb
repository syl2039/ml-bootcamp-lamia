{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importações necessárias\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import LSTM, Embedding, Bidirectional, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['you can dance, you can jive',\n",
       " 'having the time of your life',\n",
       " 'ooh, see that girl, watch that scene',\n",
       " 'digging the dancing queen',\n",
       " '',\n",
       " 'friday night and the lights are low',\n",
       " 'looking out for a place to go',\n",
       " 'where they play the right music',\n",
       " 'getting in the swing',\n",
       " 'you come to look for a king',\n",
       " '',\n",
       " 'anybody could be that guy',\n",
       " \"night is young and the music's high\",\n",
       " 'with a bit of rock music',\n",
       " 'everything is fine',\n",
       " \"you're in the mood for a dance\",\n",
       " 'and when you get the chance',\n",
       " '',\n",
       " 'you are the dancing queen',\n",
       " 'young and sweet, only seventeen',\n",
       " 'dancing queen',\n",
       " 'feel the beat from the tambourine, oh, yeah',\n",
       " '',\n",
       " 'you can dance, you can jive',\n",
       " 'having the time of your life',\n",
       " 'ooh, see that girl, watch that scene',\n",
       " 'digging the dancing queen',\n",
       " '',\n",
       " \"you're a teaser, you turn them on\",\n",
       " 'leave them burning and then you are gone',\n",
       " 'looking out for another, anyone will do',\n",
       " \"you're in the mood for a dance\",\n",
       " 'and when you get the chance',\n",
       " '',\n",
       " 'you are the dancing queen',\n",
       " 'young and sweet, only seventeen',\n",
       " 'dancing queen',\n",
       " 'feel the beat from the tambourine, oh, yeah',\n",
       " '',\n",
       " 'you can dance, you can jive',\n",
       " 'having the time of your life',\n",
       " 'ooh, see that girl, watch that scene',\n",
       " 'digging the dancing queen',\n",
       " 'digging the dancing queen']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer() # Instanciando o tokenizer\n",
    "# Carregamento do arquivo teste\n",
    "with open(\"dancing_queen.txt\", \"r\") as f:\n",
    "    texto = f.read()\n",
    "texto = texto.lower().split(\"\\n\") # Separa pelas quebras de linha e deixa as letras maiusculas minusculas\n",
    "texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2],\n",
       " [2, 7],\n",
       " [2, 7, 9],\n",
       " [2, 7, 9, 2],\n",
       " [2, 7, 9, 2, 7],\n",
       " [15],\n",
       " [15, 1],\n",
       " [15, 1, 16],\n",
       " [15, 1, 16, 11],\n",
       " [15, 1, 16, 11, 17],\n",
       " [19],\n",
       " [19, 20],\n",
       " [19, 20, 5],\n",
       " [19, 20, 5, 21],\n",
       " [19, 20, 5, 21, 22],\n",
       " [19, 20, 5, 21, 22, 5],\n",
       " [12],\n",
       " [12, 1],\n",
       " [12, 1, 3],\n",
       " [47],\n",
       " [47, 27],\n",
       " [47, 27, 6],\n",
       " [47, 27, 6, 1],\n",
       " [47, 27, 6, 1, 48],\n",
       " [47, 27, 6, 1, 48, 13],\n",
       " [28],\n",
       " [28, 29],\n",
       " [28, 29, 10],\n",
       " [28, 29, 10, 8],\n",
       " [28, 29, 10, 8, 50],\n",
       " [28, 29, 10, 8, 50, 30],\n",
       " [52],\n",
       " [52, 53],\n",
       " [52, 53, 54],\n",
       " [52, 53, 54, 1],\n",
       " [52, 53, 54, 1, 55],\n",
       " [56],\n",
       " [56, 24],\n",
       " [56, 24, 1],\n",
       " [2],\n",
       " [2, 58],\n",
       " [2, 58, 30],\n",
       " [2, 58, 30, 59],\n",
       " [2, 58, 30, 59, 10],\n",
       " [2, 58, 30, 59, 10, 8],\n",
       " [61],\n",
       " [61, 62],\n",
       " [61, 62, 63],\n",
       " [61, 62, 63, 5],\n",
       " [27],\n",
       " [27, 32],\n",
       " [27, 32, 25],\n",
       " [27, 32, 25, 6],\n",
       " [27, 32, 25, 6, 1],\n",
       " [27, 32, 25, 6, 1, 65],\n",
       " [67],\n",
       " [67, 8],\n",
       " [67, 8, 68],\n",
       " [67, 8, 68, 11],\n",
       " [67, 8, 68, 11, 69],\n",
       " [70],\n",
       " [70, 32],\n",
       " [26],\n",
       " [26, 24],\n",
       " [26, 24, 1],\n",
       " [26, 24, 1, 33],\n",
       " [26, 24, 1, 33, 10],\n",
       " [26, 24, 1, 33, 10, 8],\n",
       " [6],\n",
       " [6, 34],\n",
       " [6, 34, 2],\n",
       " [6, 34, 2, 35],\n",
       " [6, 34, 2, 35, 1],\n",
       " [2],\n",
       " [2, 13],\n",
       " [2, 13, 1],\n",
       " [2, 13, 1, 3],\n",
       " [25],\n",
       " [25, 6],\n",
       " [25, 6, 37],\n",
       " [25, 6, 37, 38],\n",
       " [3],\n",
       " [40],\n",
       " [40, 1],\n",
       " [40, 1, 41],\n",
       " [40, 1, 41, 42],\n",
       " [40, 1, 41, 42, 1],\n",
       " [40, 1, 41, 42, 1, 43],\n",
       " [40, 1, 41, 42, 1, 43, 44],\n",
       " [2],\n",
       " [2, 7],\n",
       " [2, 7, 9],\n",
       " [2, 7, 9, 2],\n",
       " [2, 7, 9, 2, 7],\n",
       " [15],\n",
       " [15, 1],\n",
       " [15, 1, 16],\n",
       " [15, 1, 16, 11],\n",
       " [15, 1, 16, 11, 17],\n",
       " [19],\n",
       " [19, 20],\n",
       " [19, 20, 5],\n",
       " [19, 20, 5, 21],\n",
       " [19, 20, 5, 21, 22],\n",
       " [19, 20, 5, 21, 22, 5],\n",
       " [12],\n",
       " [12, 1],\n",
       " [12, 1, 3],\n",
       " [26],\n",
       " [26, 8],\n",
       " [26, 8, 72],\n",
       " [26, 8, 72, 2],\n",
       " [26, 8, 72, 2, 73],\n",
       " [26, 8, 72, 2, 73, 46],\n",
       " [75],\n",
       " [75, 46],\n",
       " [75, 46, 76],\n",
       " [75, 46, 76, 6],\n",
       " [75, 46, 76, 6, 77],\n",
       " [75, 46, 76, 6, 77, 2],\n",
       " [75, 46, 76, 6, 77, 2, 13],\n",
       " [28],\n",
       " [28, 29],\n",
       " [28, 29, 10],\n",
       " [28, 29, 10, 79],\n",
       " [28, 29, 10, 79, 80],\n",
       " [28, 29, 10, 79, 80, 81],\n",
       " [26],\n",
       " [26, 24],\n",
       " [26, 24, 1],\n",
       " [26, 24, 1, 33],\n",
       " [26, 24, 1, 33, 10],\n",
       " [26, 24, 1, 33, 10, 8],\n",
       " [6],\n",
       " [6, 34],\n",
       " [6, 34, 2],\n",
       " [6, 34, 2, 35],\n",
       " [6, 34, 2, 35, 1],\n",
       " [2],\n",
       " [2, 13],\n",
       " [2, 13, 1],\n",
       " [2, 13, 1, 3],\n",
       " [25],\n",
       " [25, 6],\n",
       " [25, 6, 37],\n",
       " [25, 6, 37, 38],\n",
       " [3],\n",
       " [40],\n",
       " [40, 1],\n",
       " [40, 1, 41],\n",
       " [40, 1, 41, 42],\n",
       " [40, 1, 41, 42, 1],\n",
       " [40, 1, 41, 42, 1, 43],\n",
       " [40, 1, 41, 42, 1, 43, 44],\n",
       " [2],\n",
       " [2, 7],\n",
       " [2, 7, 9],\n",
       " [2, 7, 9, 2],\n",
       " [2, 7, 9, 2, 7],\n",
       " [15],\n",
       " [15, 1],\n",
       " [15, 1, 16],\n",
       " [15, 1, 16, 11],\n",
       " [15, 1, 16, 11, 17],\n",
       " [19],\n",
       " [19, 20],\n",
       " [19, 20, 5],\n",
       " [19, 20, 5, 21],\n",
       " [19, 20, 5, 21, 22],\n",
       " [19, 20, 5, 21, 22, 5],\n",
       " [12],\n",
       " [12, 1],\n",
       " [12, 1, 3],\n",
       " [12],\n",
       " [12, 1],\n",
       " [12, 1, 3]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.fit_on_texts(texto) # Aplica o tokenizer ao texto\n",
    "sequences = []\n",
    "for line in texto:\n",
    "    token = tokenizer.texts_to_sequences([line])[0]# Cria uma lista de tokens para cada linha\n",
    "    for i in range(1, len(token)):\n",
    "        sequences.append(token[:i:+1])# Pega os valores até i+1\n",
    "sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = max([len(x) for x in sequences]) # Pega a maior sequencia \n",
    "sequences = np.array(pad_sequences(sequences, maxlen = max_len, padding='pre')) # Adiciona zeros as esqueradas para todos ficarem com o mesmo tamanho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "npalavras = len(tokenizer.word_index) +  1\n",
    "xs = sequences[:, :-1]\n",
    "labels = sequences[:, -1]\n",
    "ys = tf.keras.utils.to_categorical(labels, num_classes=npalavras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - accuracy: 0.0764 - loss: 4.2737\n",
      "Epoch 2/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1545 - loss: 3.7050\n",
      "Epoch 3/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.3163 - loss: 2.9045\n",
      "Epoch 4/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.3475 - loss: 2.3571\n",
      "Epoch 5/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5799 - loss: 1.4779\n",
      "Epoch 6/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6870 - loss: 1.2297\n",
      "Epoch 7/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7230 - loss: 0.9970\n",
      "Epoch 8/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7323 - loss: 0.9212\n",
      "Epoch 9/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8047 - loss: 0.6688\n",
      "Epoch 10/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7774 - loss: 0.7897\n",
      "Epoch 11/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7621 - loss: 0.7419\n",
      "Epoch 12/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7476 - loss: 0.7726\n",
      "Epoch 13/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7668 - loss: 0.7158\n",
      "Epoch 14/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8067 - loss: 0.6428\n",
      "Epoch 15/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8326 - loss: 0.5951\n",
      "Epoch 16/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7891 - loss: 0.6505\n",
      "Epoch 17/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7958 - loss: 0.6313\n",
      "Epoch 18/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8192 - loss: 0.5654\n",
      "Epoch 19/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7976 - loss: 0.5455\n",
      "Epoch 20/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7876 - loss: 0.6309\n",
      "Epoch 21/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8164 - loss: 0.5855\n",
      "Epoch 22/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7988 - loss: 0.5917\n",
      "Epoch 23/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7758 - loss: 0.6762\n",
      "Epoch 24/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7912 - loss: 0.6439\n",
      "Epoch 25/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7827 - loss: 0.6571\n",
      "Epoch 26/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7708 - loss: 0.7117\n",
      "Epoch 27/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7732 - loss: 0.7253\n",
      "Epoch 28/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7908 - loss: 0.6399\n",
      "Epoch 29/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7699 - loss: 0.7202\n",
      "Epoch 30/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8137 - loss: 0.5984\n",
      "Epoch 31/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7831 - loss: 0.6314\n",
      "Epoch 32/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8036 - loss: 0.6379\n",
      "Epoch 33/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7881 - loss: 0.6853\n",
      "Epoch 34/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7543 - loss: 0.7393\n",
      "Epoch 35/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8010 - loss: 0.6179\n",
      "Epoch 36/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7959 - loss: 0.6059\n",
      "Epoch 37/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7900 - loss: 0.5890\n",
      "Epoch 38/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8017 - loss: 0.6412\n",
      "Epoch 39/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8089 - loss: 0.6139\n",
      "Epoch 40/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7687 - loss: 0.7358\n",
      "Epoch 41/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8027 - loss: 0.6353\n",
      "Epoch 42/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8131 - loss: 0.6029\n",
      "Epoch 43/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7534 - loss: 0.7146\n",
      "Epoch 44/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7606 - loss: 0.6614\n",
      "Epoch 45/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7943 - loss: 0.6221\n",
      "Epoch 46/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7826 - loss: 0.6717\n",
      "Epoch 47/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7570 - loss: 0.7490\n",
      "Epoch 48/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7763 - loss: 0.6542\n",
      "Epoch 49/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8021 - loss: 0.6027\n",
      "Epoch 50/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7953 - loss: 0.5624\n",
      "Epoch 51/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7717 - loss: 0.6853\n",
      "Epoch 52/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7431 - loss: 0.7606\n",
      "Epoch 53/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8210 - loss: 0.5531\n",
      "Epoch 54/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7790 - loss: 0.6854\n",
      "Epoch 55/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7713 - loss: 0.7139\n",
      "Epoch 56/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7709 - loss: 0.6422\n",
      "Epoch 57/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7790 - loss: 0.6365\n",
      "Epoch 58/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7897 - loss: 0.6483\n",
      "Epoch 59/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7904 - loss: 0.7027\n",
      "Epoch 60/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7832 - loss: 0.6778\n",
      "Epoch 61/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7766 - loss: 0.6842\n",
      "Epoch 62/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7989 - loss: 0.5969\n",
      "Epoch 63/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7905 - loss: 0.6770\n",
      "Epoch 64/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8041 - loss: 0.6525\n",
      "Epoch 65/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8092 - loss: 0.5880\n",
      "Epoch 66/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7878 - loss: 0.6341\n",
      "Epoch 67/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8087 - loss: 0.5692\n",
      "Epoch 68/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7789 - loss: 0.6867\n",
      "Epoch 69/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7477 - loss: 0.7706\n",
      "Epoch 70/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8006 - loss: 0.5793\n",
      "Epoch 71/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7958 - loss: 0.6064\n",
      "Epoch 72/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7752 - loss: 0.7323\n",
      "Epoch 73/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7802 - loss: 0.6966\n",
      "Epoch 74/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8457 - loss: 0.5071\n",
      "Epoch 75/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8004 - loss: 0.5998\n",
      "Epoch 76/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7916 - loss: 0.6264\n",
      "Epoch 77/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7878 - loss: 0.6558\n",
      "Epoch 78/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7803 - loss: 0.6626\n",
      "Epoch 79/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8220 - loss: 0.5599\n",
      "Epoch 80/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7731 - loss: 0.6796\n",
      "Epoch 81/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7755 - loss: 0.7248\n",
      "Epoch 82/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8039 - loss: 0.5897\n",
      "Epoch 83/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7892 - loss: 0.6420\n",
      "Epoch 84/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7593 - loss: 0.7461\n",
      "Epoch 85/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7942 - loss: 0.6612\n",
      "Epoch 86/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8212 - loss: 0.5714\n",
      "Epoch 87/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7861 - loss: 0.5689\n",
      "Epoch 88/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7846 - loss: 0.6925\n",
      "Epoch 89/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7760 - loss: 0.6752\n",
      "Epoch 90/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7693 - loss: 0.6738\n",
      "Epoch 91/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8048 - loss: 0.6081\n",
      "Epoch 92/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7766 - loss: 0.6668\n",
      "Epoch 93/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8120 - loss: 0.5903\n",
      "Epoch 94/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7642 - loss: 0.7111\n",
      "Epoch 95/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8072 - loss: 0.6280\n",
      "Epoch 96/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7219 - loss: 0.7926\n",
      "Epoch 97/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8014 - loss: 0.6396\n",
      "Epoch 98/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8347 - loss: 0.5351\n",
      "Epoch 99/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8183 - loss: 0.5485\n",
      "Epoch 100/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8098 - loss: 0.5732\n"
     ]
    }
   ],
   "source": [
    "model = Sequential() # Cria um modelo sequencial\n",
    "model.add(Embedding(npalavras, 240, input_length=max_len-1)) # Camada de embedding\n",
    "model.add(Bidirectional(LSTM(150))) # camada capaz de aprender dependencias a longo prazo\n",
    "model.add(Dense(npalavras, activation='softmax')) # Camada densa \n",
    "adam = Adam(learning_rate=0.01) # Otimizado com a taxa de apredizado personalizada\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy']) # Compilação\n",
    "history = model.fit(xs, ys, epochs=100, verbose=1) # treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Just a test they play the right right right tambourine oh oh them music's music's        \n"
     ]
    }
   ],
   "source": [
    "seed_text = \"Just a test\" # Frase inicial\n",
    "next_words = 20 # Número de palavras a serem escolhidas\n",
    "for _ in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_len-1, padding='pre')\n",
    "    predicted = model.predict(token_list, verbose=0) # Lista com probabilidades de cada palavra\n",
    "    predicted_class = predicted.argmax(axis=-1) # Pega a palavra com maior probabilidade\n",
    "    output_word = ''\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted_class:\n",
    "            output_word = word\n",
    "            break\n",
    "    seed_text+=\" \" + output_word # Monta a frase\n",
    "print(seed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
